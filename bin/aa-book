#!/bin/bash
# aa-book: Full Anna's Archive â†’ pdf-brain pipeline
# Usage: aa-book <command> [args...]

set -e

COOKIE_FILE="${HOME}/.config/annas-archive/cookies.txt"
SECRET_FILE="${HOME}/.config/annas-archive/secret.txt"
CONFIG_DIR="${HOME}/.config/annas-archive"
BASE_URL="https://annas-archive.pm"
INCOMING_DIR="${HOME}/clawd/data/pdf-brain/incoming"
PROGRESS_LOG="/tmp/aa-book-progress.log"

mkdir -p "$CONFIG_DIR" "$INCOMING_DIR"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

log() { echo -e "${GREEN}[$(date +%H:%M:%S)]${NC} $1" | tee -a "$PROGRESS_LOG"; }
warn() { echo -e "${YELLOW}[$(date +%H:%M:%S)]${NC} $1" | tee -a "$PROGRESS_LOG"; }
error() { echo -e "${RED}[$(date +%H:%M:%S)]${NC} $1" | tee -a "$PROGRESS_LOG"; }
status() { echo -e "${CYAN}[STATUS]${NC} $1" | tee -a "$PROGRESS_LOG"; }

check_login() {
    [[ -f "$COOKIE_FILE" ]] && curl -s -o /dev/null -w '%{http_code}' -b "$COOKIE_FILE" "${BASE_URL}/account/" | grep -q "200"
}

do_login() {
    [[ ! -f "$SECRET_FILE" ]] && { error "No secret key at $SECRET_FILE"; exit 1; }
    log "Logging in..."
    curl -s -c "$COOKIE_FILE" -b "$COOKIE_FILE" -L -X POST \
        -d "key=$(cat "$SECRET_FILE")" "${BASE_URL}/account/" > /dev/null
    check_login || { error "Login failed"; exit 1; }
    log "Login successful"
}

search_books() {
    local query="$1"
    local format_filter="${2:-}"  # Optional: pdf, epub, mobi

    log "Searching: $query"
    [[ -n "$format_filter" ]] && log "Format filter: $format_filter"

    # Fetch search page
    local html=$(curl -s -b "$COOKIE_FILE" "${BASE_URL}/search?q=$(echo "$query" | sed 's/ /+/g')")

    # Extract results with format, size, title
    # Pattern: /md5/HASH with nearby format and size info
    echo "$html" | python3 -c "
import sys
import re
from html import unescape

html = sys.stdin.read()
format_filter = '$format_filter'.lower()

# Find all book entries - look for md5 links with context
pattern = r'href=\"/md5/([a-f0-9]{32})\"[^>]*>([^<]+)</a>.*?(\d+(?:\.\d+)?\s*[KMG]?B).*?(pdf|epub|mobi|djvu|azw3)'
matches = re.findall(pattern, html, re.IGNORECASE | re.DOTALL)

seen = set()
results = []
for md5, title, size, fmt in matches:
    if md5 in seen:
        continue
    seen.add(md5)

    title = unescape(title.strip())[:60]
    fmt = fmt.lower()

    # Apply format filter
    if format_filter and fmt != format_filter:
        continue

    # Color code: green for PDF (no conversion), yellow for others
    if fmt == 'pdf':
        fmt_display = f'\033[32m{fmt}\033[0m'
    else:
        fmt_display = f'\033[33m{fmt}\033[0m'

    results.append((md5, title, size, fmt, fmt_display))

# Sort: PDFs first, then by format
results.sort(key=lambda x: (0 if x[3] == 'pdf' else 1, x[3]))

for md5, title, size, fmt, fmt_display in results[:15]:
    print(f'{md5}  {fmt_display:12} {size:>8}  {title}')
" 2>/dev/null || {
        # Fallback to simple extraction if python parsing fails
        echo "$html" | grep -oP 'href="/md5/[a-f0-9]{32}"' | \
            sed 's/href="\/md5\///; s/"$//' | head -10 | sort -u
    }

    echo ""
    echo "Usage: aa-book add <md5> \"reason for adding\""
    echo "       aa-book add <md5> \"reason\" -b  # background mode"
}

download_book() {
    local md5="$1"
    local output_dir="${2:-$INCOMING_DIR}"
    local max_retries=3
    local timeout=60
    
    status "Downloading md5: $md5"
    
    # Track daily downloads (25/day limit)
    local today=$(date +%Y-%m-%d)
    local count_file="${CONFIG_DIR}/download_count_${today}.txt"
    local count=$(cat "$count_file" 2>/dev/null || echo 0)
    
    if [[ $count -ge 25 ]]; then
        error "Daily download limit reached (25/day). Try tomorrow."
        return 1
    fi
    
    local download_url=""
    local server=0
    
    # Try different servers on failure
    for attempt in $(seq 1 $max_retries); do
        status "Attempt $attempt: Getting download URL (server $server)..."
        
        download_url=$(curl -s -I -b "$COOKIE_FILE" --connect-timeout 10 --max-time 30 \
            "${BASE_URL}/fast_download/${md5}/0/${server}" 2>/dev/null | \
            grep -i '^location:' | sed 's/location: //i' | tr -d '\r\n')
        
        if [[ -n "$download_url" && "$download_url" != *"not_member"* ]]; then
            break
        fi
        
        warn "Server $server failed, trying next..."
        server=$((server + 1))
        [[ $server -gt 5 ]] && server=0
        sleep 2
    done
    
    if [[ -z "$download_url" || "$download_url" == *"not_member"* ]]; then
        error "Could not get download URL after $max_retries attempts"
        return 1
    fi
    
    local orig_filename=$(echo "$download_url" | sed 's/.*\///' | python3 -c "import sys, urllib.parse; print(urllib.parse.unquote(sys.stdin.read().strip()))")
    
    # Shorten filename: extract title and extension only
    local extension="${orig_filename##*.}"
    local title=$(echo "$orig_filename" | sed 's/ -- .*//; s/[^a-zA-Z0-9 ]//g' | cut -c1-80)
    local filename="${title}.${extension}"
    local filepath="${output_dir}/${filename}"
    
    log "Downloading: $orig_filename"
    log "Saving as: $filename"
    log "Timeout: ${timeout}s"
    
    # Download with timeout and retry
    for attempt in $(seq 1 $max_retries); do
        if curl -L -o "$filepath" "$download_url" --connect-timeout 15 --max-time 300 --progress-bar 2>&1; then
            # Verify file was actually downloaded
            if [[ -f "$filepath" && $(stat -c%s "$filepath" 2>/dev/null || echo 0) -gt 1000 ]]; then
                # Increment download count
                echo $((count + 1)) > "$count_file"
                log "Download count today: $((count + 1))/25"
                break
            fi
        fi
        warn "Download attempt $attempt failed, retrying..."
        rm -f "$filepath" 2>/dev/null
        sleep 3
    done
    
    if [[ ! -f "$filepath" ]]; then
        error "Download failed after $max_retries attempts"
        return 1
    fi
    
    # Convert epub/mobi to pdf
    if [[ "$extension" == "epub" || "$extension" == "mobi" ]] && command -v ebook-convert &> /dev/null; then
        local pdf_path="${filepath%.*}.pdf"
        status "Converting $extension to PDF..."
        if timeout 120 ebook-convert "$filepath" "$pdf_path" --pdf-page-numbers 2>&1 | tail -3; then
            [[ -f "$pdf_path" ]] && { rm "$filepath"; filepath="$pdf_path"; log "Converted to PDF"; }
        else
            warn "Conversion failed, keeping original"
        fi
    fi
    
    echo "$filepath"
}

ingest_book() {
    local filepath="$1"
    local reason="$2"
    
    status "Ingesting into pdf-brain: $filepath"
    
    # Verify file exists
    if [[ ! -f "$filepath" ]]; then
        error "File not found: $filepath"
        return 1
    fi
    
    # Run pdf-brain add
    local output=$(pdf-brain add "$filepath" 2>&1)
    echo "$output" >> "$PROGRESS_LOG"
    
    if echo "$output" | grep -q "DocumentExistsError"; then
        warn "Book already exists in pdf-brain"
    elif echo "$output" | grep -q "Error"; then
        warn "Ingestion had errors - check log"
    else
        log "Ingestion complete"
    fi
    
    # Extract title for memory
    local title=$(basename "$filepath" .pdf | sed 's/_/ /g')
    
    echo "$title"
}

log_memory() {
    local title="$1"
    local reason="$2"
    local md5="$3"
    
    status "Logging to hivemind..."
    
    local memory="Book added to pdf-brain ($(date +%Y-%m-%d)): \"$title\"
MD5: $md5
Reason: $reason
Use: Search pdf-brain for concepts from this book when relevant."

    # Use swarm memory store if available
    if command -v swarm &> /dev/null; then
        swarm memory store "$memory" --tags "pdf-brain,books,reference" 2>&1 | tee -a "$PROGRESS_LOG"
    else
        echo "$memory" >> "${HOME}/clawd/memory/books-added.md"
        log "Logged to ~/clawd/memory/books-added.md"
    fi
}

cleanup() {
    local filepath="$1"
    if [[ -f "$filepath" ]]; then
        rm "$filepath"
        log "Cleaned up: $filepath"
    fi
}

# Full pipeline: download â†’ convert â†’ ingest â†’ log â†’ cleanup
add_book() {
    local md5="$1"
    local reason="${2:-Reference material}"
    local background="${3:-false}"
    
    # Clear progress log
    echo "=== aa-book add $md5 ===" > "$PROGRESS_LOG"
    echo "Started: $(date)" >> "$PROGRESS_LOG"
    echo "Reason: $reason" >> "$PROGRESS_LOG"
    echo "" >> "$PROGRESS_LOG"
    
    if [[ "$background" == "--background" || "$background" == "-b" ]]; then
        nohup bash -c "
            export PATH=\"\$HOME/.local/bin:\$PATH\"
            source ~/.clawdbot/skills/annas-archive/aa-book.sh
            _run_pipeline '$md5' '$reason'
        " >> "$PROGRESS_LOG" 2>&1 &
        local pid=$!
        echo "$pid" > "${CONFIG_DIR}/current_job.pid"
        echo "ðŸš€ Running in background (PID: $pid)"
        echo "   Monitor: tail -f $PROGRESS_LOG"
        echo "   Or: aa-book status"
        return 0
    fi
    
    _run_pipeline "$md5" "$reason"
}

# Check status of background job
check_status() {
    local pid_file="${CONFIG_DIR}/current_job.pid"
    
    if [[ -f "$pid_file" ]]; then
        local pid=$(cat "$pid_file")
        if ps -p "$pid" > /dev/null 2>&1; then
            echo "ðŸ”„ Job running (PID: $pid)"
            echo ""
            echo "Recent progress:"
            tail -10 "$PROGRESS_LOG"
        else
            echo "âœ… Job completed"
            echo ""
            tail -20 "$PROGRESS_LOG" | grep -E '(STATUS|Complete|Error|complete)'
            rm "$pid_file"
        fi
    else
        echo "No active job"
        [[ -f "$PROGRESS_LOG" ]] && echo "Last log: tail -f $PROGRESS_LOG"
    fi
    
    # Show daily quota
    local today=$(date +%Y-%m-%d)
    local count=$(cat "${CONFIG_DIR}/download_count_${today}.txt" 2>/dev/null || echo 0)
    echo ""
    echo "ðŸ“Š Downloads today: $count/25"
}

_run_pipeline() {
    local md5="$1"
    local reason="$2"
    
    check_login || do_login
    
    local filepath=$(download_book "$md5")
    local title=$(ingest_book "$filepath" "$reason")
    log_memory "$title" "$reason" "$md5"
    cleanup "$filepath"
    
    echo ""
    status "âœ… Complete: $title"
    echo "Completed: $(date)" >> "$PROGRESS_LOG"
}

show_help() {
    echo "aa-book - Anna's Archive â†’ pdf-brain pipeline"
    echo ""
    echo "Commands:"
    echo "  search <query> [format]     Search for books (format: pdf, epub, mobi)"
    echo "  download <md5> [dir]        Download only (with epubâ†’pdf conversion)"
    echo "  add <md5> \"<reason>\"        Full pipeline: download â†’ ingest â†’ log â†’ cleanup"
    echo "  add <md5> \"<reason>\" -b     Run in background (non-blocking)"
    echo "  status                      Check background job & daily quota"
    echo "  login                       Force re-login"
    echo ""
    echo "Examples:"
    echo "  aa-book search 'designing data intensive'       # All formats (PDFs first)"
    echo "  aa-book search 'clean architecture' pdf         # PDFs only"
    echo "  aa-book add abc123def456 'Distributed systems reference' -b"
    echo "  aa-book status"
    echo ""
    echo "Daily limit: 25 fast downloads"
    echo "Progress log: $PROGRESS_LOG"
}

# Main
case "${1:-}" in
    search)
        shift
        check_login || do_login
        # Check if last arg is a format filter
        if [[ "$#" -ge 2 && "${!#}" =~ ^(pdf|epub|mobi)$ ]]; then
            format="${!#}"
            query="${*:1:$#-1}"
            search_books "$query" "$format"
        else
            search_books "$*"
        fi
        ;;
    download) check_login || do_login; download_book "$2" "${3:-}" ;;
    add) check_login || do_login; add_book "$2" "$3" "$4" ;;
    status) check_status ;;
    login) do_login ;;
    help|--help|-h) show_help ;;
    *) show_help ;;
esac
